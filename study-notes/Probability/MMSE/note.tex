\documentclass[11pt]{article}
\usepackage[UTF8]{ctex}
\usepackage[a4paper, margin=1in]{geometry}
\usepackage{amsmath, amssymb, amsthm, mathtools}
\usepackage{bm}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage[colorlinks=true, linkcolor=blue]{hyperref}


% 页面设置
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{MMSE估计理论}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}

% 标题格式
\titleformat{\section}{\large\bfseries\color{blue!70!black}}{\thesection}{1em}{}
\titleformat{\subsection}{\normalsize\bfseries\color{blue!50!black}}{\thesubsection}{1em}{}

% 定理环境
\tcbuselibrary{theorems}
\newtcbtheorem[number within=section]{definition}{定义}%
{colback=blue!5!white,colframe=blue!75!black,fonttitle=\bfseries}{def}
\newtcbtheorem[number within=section]{theorem}{定理}%
{colback=green!5!white,colframe=green!75!black,fonttitle=\bfseries}{thm}
\newtcbtheorem[number within=section]{lemma}{引理}%
{colback=orange!5!white,colframe=orange!75!black,fonttitle=\bfseries}{lem}
\newtcbtheorem[number within=section]{example}{例题}%
{colback=purple!5!white,colframe=purple!75!black,fonttitle=\bfseries}{ex}
\newtcbtheorem[number within=section]{remark}{注记}%
{colback=gray!5!white,colframe=gray!75!black,fonttitle=\bfseries}{rem}

% 数学符号
\renewcommand{\vec}[1]{\bm{#1}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\trace}{\text{tr}}
\newcommand{\argmin}{\operatorname*{argmin}}
\newcommand{\normal}{\mathcal{N}}
\newcommand{\reals}{\mathbb{R}}

\title{\Large\textbf{最小均方误差估计理论\\{\normalsize Minimum Mean Square Error (MMSE) Estimation}}}
\author{统计信号处理笔记}
\date{\today}

\begin{document}
\maketitle

\tableofcontents
\vspace{0.5cm}

\section{引言与动机}

在统计学和信号处理中，我们经常面临从噪声观测中估计未知参数或信号的问题。最小均方误差（MMSE）估计是一种基础且重要的估计准则，它在理论上具有最优性，在实践中具有广泛的应用价值。

\begin{remark}{MMSE的重要性}{rem:importance}
MMSE估计不仅提供了理论上的最优解，还为许多实际算法（如Wiener滤波、Kalman滤波等）提供了理论基础。
\end{remark}

\section{基本概念与定义}

\begin{definition}{MMSE估计器}{def:mmse}
设$\vec{X} \in \reals^n$是未知随机向量，$\vec{Y} \in \reals^m$是观测向量。MMSE估计器$\hat{\vec{X}}_{\text{MMSE}}$定义为最小化均方误差的估计器：
\begin{equation}
\hat{\vec{X}}_{\text{MMSE}} = \argmin_{\hat{\vec{X}}(\vec{Y})} \E\left[ \|\vec{X} - \hat{\vec{X}}(\vec{Y})\|^2 \right]
\end{equation}
其中期望运算是关于联合分布$p(\vec{X}, \vec{Y})$进行的，$\|\cdot\|$表示欧几里得范数。
\end{definition}

\begin{definition}{均方误差}{def:mse}
对于任意估计器$\hat{\vec{X}}(\vec{Y})$，其均方误差定义为：
\begin{equation}
\text{MSE}(\hat{\vec{X}}) = \E\left[ \|\vec{X} - \hat{\vec{X}}(\vec{Y})\|^2 \right] = \E\left[ \sum_{i=1}^n (X_i - \hat{X}_i(\vec{Y}))^2 \right]
\end{equation}
\end{definition}

\section{核心理论结果}

\subsection{MMSE估计器的最优性}

\begin{theorem}{MMSE估计器的解析形式}{thm:mmse_solution}
MMSE估计器由条件期望给出：
\begin{equation}
\hat{\vec{X}}_{\text{MMSE}}(\vec{Y}) = \E[\vec{X} \mid \vec{Y}]
\end{equation}
此时的最小均方误差为：
\begin{equation}
\text{MMSE} = \E\left[ \|\vec{X} - \E[\vec{X} \mid \vec{Y}]\|^2 \right]
\end{equation}
\end{theorem}

\begin{proof}
对于任意估计器$\hat{\vec{X}}(\vec{Y})$，将估计误差分解为：
\begin{equation}
\vec{X} - \hat{\vec{X}} = \underbrace{(\vec{X} - \E[\vec{X} \mid \vec{Y}])}_{\vec{e}_{\text{irr}}} + \underbrace{(\E[\vec{X} \mid \vec{Y}] - \hat{\vec{X}})}_{\vec{e}_{\text{red}}}
\end{equation}

其中$\vec{e}_{\text{irr}}$为不可约误差，$\vec{e}_{\text{red}}$为可约误差。

计算均方误差：
\begin{align}
\E[\|\vec{X} - \hat{\vec{X}}\|^2] &= \E[\|\vec{e}_{\text{irr}} + \vec{e}_{\text{red}}\|^2] \\
&= \E[\|\vec{e}_{\text{irr}}\|^2] + \E[\|\vec{e}_{\text{red}}\|^2] + 2\E[\vec{e}_{\text{irr}}^T \vec{e}_{\text{red}}]
\end{align}

关键是证明交叉项为零。利用条件期望的性质：
\begin{align}
\E[\vec{e}_{\text{irr}}^T \vec{e}_{\text{red}}] &= \E\left[ (\vec{X} - \E[\vec{X} \mid \vec{Y}])^T (\E[\vec{X} \mid \vec{Y}] - \hat{\vec{X}}) \right] \\
&= \E\left[ \E[(\vec{X} - \E[\vec{X} \mid \vec{Y}])^T (\E[\vec{X} \mid \vec{Y}] - \hat{\vec{X}}) \mid \vec{Y}] \right] \\
&= \E\left[ (\E[\vec{X} \mid \vec{Y}] - \hat{\vec{X}})^T \E[(\vec{X} - \E[\vec{X} \mid \vec{Y}]) \mid \vec{Y}] \right] \\
&= \E\left[ (\E[\vec{X} \mid \vec{Y}] - \hat{\vec{X}})^T \cdot \vec{0} \right] = 0
\end{align}

因此：
\begin{equation}
\E[\|\vec{X} - \hat{\vec{X}}\|^2] = \underbrace{\E[\|\vec{X} - \E[\vec{X} \mid \vec{Y}]\|^2]}_{\text{不可约误差}} + \underbrace{\E[\|\E[\vec{X} \mid \vec{Y}] - \hat{\vec{X}}\|^2]}_{\geq 0}
\end{equation}

显然，当$\hat{\vec{X}} = \E[\vec{X} \mid \vec{Y}]$时，第二项为零，此时MSE达到最小值。
\end{proof}

\subsection{正交性原理}

\begin{theorem}{正交性原理}{thm:orthogonality}
MMSE估计误差$\vec{e} = \vec{X} - \hat{\vec{X}}_{\text{MMSE}}$与观测$\vec{Y}$的任意函数正交：
\begin{equation}
\E[\vec{e} \, g(\vec{Y})^T] = \mathbf{0} \quad \forall \text{可测函数 } g(\cdot)
\end{equation}
特别地，$\E[\vec{e} \mid \vec{Y}] = \vec{0}$。
\end{theorem}

\begin{proof}
由于$\vec{e} = \vec{X} - \E[\vec{X} \mid \vec{Y}]$，利用条件期望的性质：
\begin{align}
\E[\vec{e} \, g(\vec{Y})^T] &= \E\left[ \E[\vec{e} \, g(\vec{Y})^T \mid \vec{Y}] \right] \\
&= \E\left[ g(\vec{Y})^T \E[\vec{e} \mid \vec{Y}] \right] \\
&= \E\left[ g(\vec{Y})^T \E[(\vec{X} - \E[\vec{X} \mid \vec{Y}]) \mid \vec{Y}] \right] \\
&= \E\left[ g(\vec{Y})^T (\E[\vec{X} \mid \vec{Y}] - \E[\vec{X} \mid \vec{Y}]) \right] \\
&= \E\left[ g(\vec{Y})^T \cdot \vec{0} \right] = \mathbf{0}
\end{align}
\end{proof}

\begin{remark}{正交性的几何解释}{rem:geometry}
正交性原理表明，MMSE估计误差在由观测$\vec{Y}$的所有函数张成的空间中的投影为零，这是最优估计的几何特征。
\end{remark}

\section{高斯情形下的MMSE}

\subsection{联合高斯分布的MMSE}

\begin{theorem}{高斯向量的MMSE估计}{thm:gaussian_mmse}
若$\vec{X}$和$\vec{Y}$服从联合高斯分布：
\begin{equation}
\begin{bmatrix} \vec{X} \\ \vec{Y} \end{bmatrix} \sim \normal\left( 
\begin{bmatrix} \vec{\mu}_X \\ \vec{\mu}_Y \end{bmatrix}, 
\begin{bmatrix} \Sigma_{XX} & \Sigma_{XY} \\ \Sigma_{YX} & \Sigma_{YY} \end{bmatrix}
\right)
\end{equation}
则MMSE估计器为线性函数：
\begin{equation}
\hat{\vec{X}}_{\text{MMSE}} = \vec{\mu}_X + \Sigma_{XY} \Sigma_{YY}^{-1} (\vec{Y} - \vec{\mu}_Y)
\end{equation}
对应的最小均方误差为：
\begin{equation}
\text{MMSE} = \trace(\Sigma_{XX} - \Sigma_{XY} \Sigma_{YY}^{-1} \Sigma_{YX})
\end{equation}
\end{theorem}

\begin{proof}
对于联合高斯分布，条件分布$\vec{X} \mid \vec{Y}$也是高斯分布：
\begin{equation}
\vec{X} \mid \vec{Y} \sim \normal(\vec{\mu}_{X|Y}, \Sigma_{X|Y})
\end{equation}
其中：
\begin{align}
\vec{\mu}_{X|Y} &= \vec{\mu}_X + \Sigma_{XY} \Sigma_{YY}^{-1} (\vec{Y} - \vec{\mu}_Y) \\
\Sigma_{X|Y} &= \Sigma_{XX} - \Sigma_{XY} \Sigma_{YY}^{-1} \Sigma_{YX}
\end{align}

由于$\E[\vec{X} \mid \vec{Y}] = \vec{\mu}_{X|Y}$，所以MMSE估计器即为上述线性形式。

最小均方误差为：
\begin{equation}
\text{MMSE} = \E[\|\vec{X} - \E[\vec{X} \mid \vec{Y}]\|^2] = \trace(\Var(\vec{X} \mid \vec{Y})) = \trace(\Sigma_{X|Y})
\end{equation}
\end{proof}

\subsection{线性MMSE (LMMSE)估计}

\begin{definition}{线性MMSE估计器}{def:lmmse}
当估计器限制为线性形式$\hat{\vec{X}} = A\vec{Y} + \vec{b}$时，线性MMSE（LMMSE）估计器定义为：
\begin{equation}
\hat{\vec{X}}_{\text{LMMSE}} = \argmin_{A, \vec{b}} \E\left[ \|\vec{X} - A\vec{Y} - \vec{b}\|^2 \right]
\end{equation}
\end{definition}

\begin{theorem}{LMMSE估计器的解析解}{thm:lmmse_solution}
LMMSE估计器为：
\begin{align}
\hat{\vec{X}}_{\text{LMMSE}} &= \vec{\mu}_X + \Sigma_{XY} \Sigma_{YY}^{-1} (\vec{Y} - \vec{\mu}_Y) \\
A_{\text{opt}} &= \Sigma_{XY} \Sigma_{YY}^{-1} \\
\vec{b}_{\text{opt}} &= \vec{\mu}_X - A_{\text{opt}} \vec{\mu}_Y
\end{align}
\end{theorem}

\begin{proof}
将MSE展开：
\begin{align}
&\E[\|\vec{X} - A\vec{Y} - \vec{b}\|^2] \\
&= \E[\|\vec{X} - \vec{\mu}_X - A(\vec{Y} - \vec{\mu}_Y) - (\vec{b} + A\vec{\mu}_Y - \vec{\mu}_X)\|^2]
\end{align}

令$\tilde{\vec{X}} = \vec{X} - \vec{\mu}_X$，$\tilde{\vec{Y}} = \vec{Y} - \vec{\mu}_Y$，$\vec{c} = \vec{b} + A\vec{\mu}_Y - \vec{\mu}_X$，则：
\begin{equation}
\text{MSE} = \E[\|\tilde{\vec{X}} - A\tilde{\vec{Y}} - \vec{c}\|^2]
\end{equation}

对$\vec{c}$求偏导并令其为零：
\begin{equation}
\frac{\partial}{\partial \vec{c}} \text{MSE} = -2\E[\tilde{\vec{X}} - A\tilde{\vec{Y}}] = 0
\end{equation}
由于$\E[\tilde{\vec{X}}] = \E[\tilde{\vec{Y}}] = \vec{0}$，得$\vec{c}_{\text{opt}} = \vec{0}$。

对$A$求偏导并令其为零：
\begin{equation}
\frac{\partial}{\partial A} \text{MSE} = -2\E[\tilde{\vec{X}}\tilde{\vec{Y}}^T] + 2A\E[\tilde{\vec{Y}}\tilde{\vec{Y}}^T] = 0
\end{equation}
因此：
\begin{equation}
A_{\text{opt}} = \E[\tilde{\vec{X}}\tilde{\vec{Y}}^T] (\E[\tilde{\vec{Y}}\tilde{\vec{Y}}^T])^{-1} = \Sigma_{XY} \Sigma_{YY}^{-1}
\end{equation}
\end{proof}

\begin{theorem}{高斯情形下MMSE与LMMSE的等价性}{thm:gaussian_equivalence}
当$\vec{X}$和$\vec{Y}$联合高斯分布时：
\begin{equation}
\hat{\vec{X}}_{\text{MMSE}} = \hat{\vec{X}}_{\text{LMMSE}}
\end{equation}
\end{theorem}

\section{实际应用示例}

\begin{example}{一维标量估计}{ex:scalar}
考虑标量情形：$X \sim \normal(0, \sigma_X^2)$，观测模型为$Y = X + N$，其中$N \sim \normal(0, \sigma_N^2)$且$X \perp N$。

求MMSE估计器及其性能。

\textbf{解：}
首先计算必要的统计量：
\begin{align}
\mu_X &= 0, \quad \mu_Y = 0 \\
\Sigma_{XX} &= \sigma_X^2 \\
\Sigma_{YY} &= \sigma_X^2 + \sigma_N^2 \\
\Sigma_{XY} &= \Cov(X, Y) = \Cov(X, X+N) = \sigma_X^2
\end{align}

MMSE估计器为：
\begin{equation}
\hat{X}_{\text{MMSE}} = \frac{\sigma_X^2}{\sigma_X^2 + \sigma_N^2} Y = \frac{\text{SNR}}{1 + \text{SNR}} Y
\end{equation}
其中$\text{SNR} = \sigma_X^2/\sigma_N^2$为信噪比。

最小均方误差为：
\begin{equation}
\text{MMSE} = \sigma_X^2 - \frac{(\sigma_X^2)^2}{\sigma_X^2 + \sigma_N^2} = \frac{\sigma_X^2 \sigma_N^2}{\sigma_X^2 + \sigma_N^2}
\end{equation}
\end{example}

\begin{example}{向量Wiener滤波}{ex:wiener}
考虑向量观测模型：
\begin{equation}
\vec{Y} = H\vec{X} + \vec{N}
\end{equation}
其中$H \in \reals^{m \times n}$为已知矩阵，$\vec{X} \sim \normal(\vec{0}, \Sigma_X)$，$\vec{N} \sim \normal(\vec{0}, \Sigma_N)$，且$\vec{X} \perp \vec{N}$。

\textbf{解：}
计算协方差矩阵：
\begin{align}
\Sigma_{XY} &= \Cov(\vec{X}, \vec{Y}) = \Cov(\vec{X}, H\vec{X} + \vec{N}) = \Sigma_X H^T \\
\Sigma_{YY} &= \Var(\vec{Y}) = H\Sigma_X H^T + \Sigma_N
\end{align}

MMSE估计器为：
\begin{equation}
\hat{\vec{X}}_{\text{MMSE}} = \Sigma_X H^T (H\Sigma_X H^T + \Sigma_N)^{-1} \vec{Y}
\end{equation}

这正是著名的Wiener滤波器公式。
\end{example}

\section{重要性质与扩展}

\subsection{MMSE的不变性质}

\begin{theorem}{仿射变换不变性}{thm:affine_invariance}
若$\vec{Z} = A\vec{X} + \vec{b}$，则：
\begin{equation}
\hat{\vec{Z}}_{\text{MMSE}} = A\hat{\vec{X}}_{\text{MMSE}} + \vec{b}
\end{equation}
\end{theorem}

\subsection{贝叶斯观点}

从贝叶斯角度看，MMSE估计器等价于在平方损失函数下的贝叶斯估计器：
\begin{equation}
\hat{\vec{X}}_{\text{Bayes}} = \argmin_{\hat{\vec{X}}} \E_{p(\vec{X}|\vec{Y})}[L(\vec{X}, \hat{\vec{X}})]
\end{equation}
其中$L(\vec{X}, \hat{\vec{X}}) = \|\vec{X} - \hat{\vec{X}}\|^2$。

\section{计算复杂度与实现}

在实际应用中，MMSE估计器的计算复杂度主要来自：
\begin{enumerate}[itemsep=0pt]
\item 协方差矩阵的计算和存储：$O(n^2)$空间复杂度
\item 矩阵求逆运算：$O(m^3)$时间复杂度（其中$m$为观测维度）
\item 矩阵乘法运算：$O(nm^2)$时间复杂度
\end{enumerate}

对于大规模问题，可采用以下优化策略：
\begin{itemize}[itemsep=0pt]
\item 利用矩阵的特殊结构（如对角、带状等）
\item 使用迭代算法（如共轭梯度法）
\item 采用低秩近似技术
\item 利用递推算法（如Kalman滤波）
\end{itemize}

\section{总结}

MMSE估计理论为统计估计提供了坚实的理论基础。其主要优点包括：
\begin{itemize}[itemsep=0pt]
\item 理论最优性：在均方误差意义下达到最小值
\item 解析解：在高斯情形下具有闭式解
\item 几何直观：基于正交性原理的清晰几何解释
\item 广泛应用：为许多实际算法提供理论支撑
\end{itemize}

然而，MMSE估计也有其局限性：
\begin{itemize}[itemsep=0pt]
\item 需要完整的统计信息（联合分布或二阶矩）
\item 计算复杂度较高，特别是高维情形
\item 对模型假设敏感，鲁棒性有限
\end{itemize}

在实际应用中，需要根据具体问题的特点，在估计性能、计算复杂度和鲁棒性之间进行权衡。

\end{document}